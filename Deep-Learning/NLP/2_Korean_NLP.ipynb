{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어 파싱 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Print whole tree\n",
      "(S\n",
      "  (NP 철수/Noun)\n",
      "  가/Josa\n",
      "  (NP 학교/Noun)\n",
      "  에/Josa\n",
      "  (VP 갑니다/Verb)\n",
      "  ./Punctuation)\n",
      "None\n",
      "\n",
      "# Print noun phrases only\n",
      "철수\n",
      "(NP 철수/Noun)\n",
      "None\n",
      "학교\n",
      "(NP 학교/Noun)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import konlpy\n",
    "import nltk\n",
    "\n",
    "# POS tag a sentence\n",
    "sentence = u'철수가 학교에 갑니다.'\n",
    "words = konlpy.tag.Twitter().pos(sentence)\n",
    "\n",
    "# Define a chunk grammar, or chunking rules, then chunk\n",
    "# 묶어서 분석해야 하는 것을 정의한다.\n",
    "grammar = \"\"\"\n",
    "NP: {<N.*>*<Suffix>?}   # Noun phrase # 명사\n",
    "VP: {<V.*>*}            # Verb phrase # 동사\n",
    "AP: {<A.*>*}            # Adjective phrase # 형용사\n",
    "\"\"\"\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "chunks = parser.parse(words)\n",
    "print(\"# Print whole tree\")\n",
    "print(chunks.pprint())\n",
    "\n",
    "# 명사와 명사구를 출력\n",
    "\n",
    "# 문서에서의 키워드 추출이라던가, 문서 내에 존재하는 단어들의 상관 관계 등 (신조어나 제품명만 추출하고 싶을때 보통)를 분석할 때 사용\n",
    "# 동사는 이벤트에 대한 정보를 담고 있고, 명사는 객체의 정보를 담고 있기 때문이다.\n",
    "print(\"\\n# Print noun phrases only\")\n",
    "for subtree in chunks.subtrees():\n",
    "    if subtree.label()=='NP':\n",
    "        print(' '.join((e[0] for e in list(subtree))))\n",
    "        print(subtree.pprint())\n",
    "\n",
    "# Display the chunk tree\n",
    "chunks.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한국어 형태소 분석 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> 형태소 분리\n",
      "['K9전차', '가', '전방', '에', '포', '를', '발사', '하', '었습니다', '.']\n",
      "=> 형태소 분리 + 형태소 태그 부착\n",
      "[('코로나19', 'N'), ('바이러스', 'N'), ('확산', 'N'), ('이', 'J'), ('진정', 'N'), ('국면', 'N'), ('으로', 'J'), ('접어들', 'P'), ('고', 'E'), ('있', 'P'), ('습니다', 'E'), ('.', 'S')]\n",
      "=> 명사만 추출\n",
      "['코로나19', '바이러스', '확산', '진정', '국면']\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "\n",
    "hannanum = Hannanum()\n",
    "\n",
    "hannanum.morphs  # 형태소 분석\n",
    "\n",
    "print(\"=> 형태소 분리\")\n",
    "print(hannanum.morphs(u'K9전차가 전방에 포를 발사하였습니다.'))\n",
    "\n",
    "print(\"=> 형태소 분리 + 형태소 태그 부착\")\n",
    "print(hannanum.pos(u'코로나19 바이러스 확산이 진정 국면으로 접어들고 있습니다.'))\n",
    "\n",
    "print(\"=> 명사만 추출\")\n",
    "print(hannanum.nouns(u'코로나19 바이러스 확산이 진정 국면으로 접어들고 있습니다.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
