{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "glove_lstm_attention_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI5FI2lK2Ijg",
        "outputId": "9746f5bc-32c8-4c62-fe23-afa5747cbb25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from collections import Counter\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk import WordPunctTokenizer\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P4U_9J19ApX",
        "outputId": "30804b09-71e6-47a3-bc93-36bf13472a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/4AGC1DN2kyOkbOOejK9b5dbFX9P6OpUWWPe2X5v0Gq6A7GQHJ4iqlIc\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_iI9D_I2LZc",
        "outputId": "5260482d-e145-406e-fa82-57ab2f5d25c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# spam classification data loading\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/mohitgupta-omg/Kaggle-SMS-Spam-Collection-Dataset-/master/spam.csv\", filename=\"spam.csv\")\n",
        "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>v1</th>\n",
              "      <th>v2</th>\n",
              "      <th>Unnamed: 2</th>\n",
              "      <th>Unnamed: 3</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     v1  ... Unnamed: 4\n",
              "0   ham  ...        NaN\n",
              "1   ham  ...        NaN\n",
              "2  spam  ...        NaN\n",
              "3   ham  ...        NaN\n",
              "4   ham  ...        NaN\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_4elvoZ-PE-",
        "outputId": "f0e9288d-b8f8-4db5-fb49-a97535f37ac1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "texts = list(data['v2'])\n",
        "labels = list(data['v1'])\n",
        "\n",
        "print(texts[:5])\n",
        "print(labels[:5])\n",
        "\n",
        "print(Counter(labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...', 'Ok lar... Joking wif u oni...', \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\", 'U dun say so early hor... U c already then say...', \"Nah I don't think he goes to usf, he lives around here though\"]\n",
            "['ham', 'ham', 'spam', 'ham', 'ham']\n",
            "Counter({'ham': 4825, 'spam': 747})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olMpgGsK89uL"
      },
      "source": [
        "# glove vector model initialize\n",
        "glove = {}\n",
        "with open('/content/drive/My Drive/Colab Notebooks/data/news_sample/glove.6B.50d.txt', 'r', encoding='utf-8') as fr:\n",
        "    for line in fr.readlines():\n",
        "        temp = line.strip().split()\n",
        "        word = temp[0]\n",
        "        vector = temp[1:]\n",
        "\n",
        "        glove[word] = list(map(float, vector))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXuFGypB8r_G"
      },
      "source": [
        "def tokenize(document):\n",
        "  words = []\n",
        "  sentences = sent_tokenize(document) # sentence tokenizing\n",
        "\n",
        "  for sentence in sentences:\n",
        "    words.extend(WordPunctTokenizer().tokenize(sentence)) # word tokenizing\n",
        "\n",
        "  return [word.lower() for word in words] # case normalization\n",
        "\n",
        "def get_vector(sentence):\n",
        "  tokens = tokenize(sentence)\n",
        "  vector = [glove[token] if token in glove.keys() else [0]*50 for token in tokens] # 50인 이유는, 지금 glove vector가 50차원짜리를 사용하고 있기 때문에 차원을 동일하게 맞춰주기 위해 50을 사용\n",
        "\n",
        "  while len(vector) < 256:\n",
        "    vector.append([0] * 50)\n",
        "  \n",
        "  return vector[:256]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b7nyL8H-Tl3"
      },
      "source": [
        "x = [get_vector(text) for text in texts]\n",
        "x_train, x_test = np.array(x[:5000]), np.array(x[5000:])\n",
        "y = [0 if label == 'spam' else 1 for label in labels]\n",
        "y_train, y_test = np.array(y[:5000]), np.array(y[5000:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9D6Pnlm-cly"
      },
      "source": [
        "input_layer = tf.keras.layers.Input(shape=(x_train.shape[1], x_train.shape[2]))\n",
        "lstm_layer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(input_layer)\n",
        "attention = tf.keras.layers.Attention()([lstm_layer, lstm_layer, lstm_layer])\n",
        "flatten = tf.keras.layers.Flatten()(attention)\n",
        "dense1_layer = tf.keras.layers.Dense(64, activation = 'relu')(flatten)\n",
        "dense2_layer = tf.keras.layers.Dense(2, activation = 'softmax')(dense1_layer)\n",
        "\n",
        "model = tf.keras.Model(inputs=input_layer, outputs=dense2_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdaBdeSb_BWC",
        "outputId": "699b0490-84ba-4c29-d68e-e39f9c75b49f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 256, 50)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) (None, 256, 256)     183296      input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_3 (Attention)         (None, 256, 256)     0           bidirectional_5[0][0]            \n",
            "                                                                 bidirectional_5[0][0]            \n",
            "                                                                 bidirectional_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 65536)        0           attention_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 64)           4194368     flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 2)            130         dense_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 4,377,794\n",
            "Trainable params: 4,377,794\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awiYcBcx_Bsm"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLK-Wkg6_FIy",
        "outputId": "daa0902e-550f-443a-a26f-49d5c1bd6cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "157/157 [==============================] - 101s 643ms/step - loss: 0.1672 - accuracy: 0.9492\n",
            "Epoch 2/2\n",
            "157/157 [==============================] - 100s 637ms/step - loss: 0.0849 - accuracy: 0.9740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd231b61630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU5TRiTM_G7E",
        "outputId": "b57f221c-2763-4f07-b4a2-1569a13cec28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "model.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18/18 - 3s - loss: 0.0775 - accuracy: 0.9790\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07751128822565079, 0.9790209531784058]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}