# 이미지 인식의 정확도를 더 높이려면
# 앙상블 학습, 학습률 감소, 데이터 확장 등이 정확도 향상에 공헌하고 있다 

# 데이터 확장 (data augmentation)
# 입력이미지(훈련이미지)를 알고리즘을 동원해 인원적으로 확장 
# 입력 이미지를 회전하거나 세로로 이동하는 등 미세한 변화를 주어 이미지의 개수를 늘리는 것
# 이는 데이터가 몇 개 없을 때 특히 효과적인 수단이다 

# 이미지 일부를 잘라내는 crop이나 좌우를 뒤집는 filp 등이 있다 
# 일반적인 이미지에는 밝기 등의 외형 변화나 확대, 축소 등의 스케일 변화도 효과적이다 
# 데이터 확장을 동원해 훈련 이미지의 개수를 늘릴 수 있다면 딥러닝 인식 수준을 개선할 수 있다 

# 층을 깊게 하는 것이 왜 중요한가 ?
# 이론적인 근거는 아직 부족한 것이 사실이다 
# 우선 층을 깊게 하는 것의 중요성은 ILSVRC로 대표되는 이미지 인식 대회의 결과에서 파악할 수 있다

# 층을 깊게 할 때의 이점 
# 신경망의 매개변수 수가 줄어단는 점이다. 이를 통해 표현력을 높일 수 있다 
# 학습의 효율성도 층을 깊게 하는 것의 이점이다. 층을 깊게 함으로써 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다는 뜻이다 

# 작은 필터를 겹쳐 신경망을 깊게 할 때의 장점은 매개변수 수를 줄여 넓은 수용 역역(receptive field)을 소화할 수 있다는데 있다 
# (수용 영역은 뉴런에 변화를 일으키는 국소적인 공간의 영역이다). 게대가 층을 거듭하면서 ReLU 등의 활서오하 함수를 합성곱 계층 사이에 
# 끼움으로써 신경망의 표현력이 개선된다. 이는 활서오하 함수가 신경망에 비선형 힘을 가하고, 비선형 함수가 겹치면서 더 복잡한 것도 
# 표현할 수 있게 되기 때문이다 

# 신경망을 깊게 하면 학습해야 할 문제를 계층적으로 분해할 수 있다. 
# 각 층이 학습해야할 문제를 더 단순한 문제로 더 단순한 문제로 대체할 수있다는 것이다 

# 층을 깊게 하면 정보를 계층적으로 전달할 수 있다는 점도 중요하다 
# 예를 들어 에지를 추출한 층의 다음 층은 에지정보를 쓸 수 있고, 더 고도의 패턴을 효과적으로 학습이라는 기대를 할 수 있다 
# 즉, 층을 깊이 함으로써 각 층이 학습해야 할 문제를 풀기 쉬운 단둔한 문제로 분해할 수 있어 효율적으로 학습이리라 기대할 수 있다 


